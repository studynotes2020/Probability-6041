{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Markov Inequality\n",
    "\n",
    "Take a random variable which is always non-negative $X \\geq 0$. For simplicity, assume it is discrete\n",
    "\n",
    "$$E[X] = \\sum_x x P_X(x)$$\n",
    "\n",
    "Set $a$ be a certain number of $x$ can take, so total expectation is $\\geq \\sum_{x \\geq a} x P_X(x)$. If we further fix x = a, then we get a smaller quantity $\\sum_{x \\geq a} a P_X(x)$ . Finally using the definition of pmf,\n",
    "\n",
    "$$E[X] \\geq a P(X \\geq a)$$\n",
    "\n",
    "This is Markov Inequality. It relates expected values to probabilities. It tells us that if the expected value is small, then the probability that x is big is also going to be small. It translates the statement of smallness of expected values into statement of smallness of probabilities\n",
    "\n",
    "\n",
    "Apply same idea to variance. Here use $a^2$ instead of $a$\n",
    "\n",
    "$$Var(x) = E[(X-\\mu)^2] \\geq a^2 P((x-\\mu)^2 \\geq a^2)$$ \n",
    "\n",
    "$\\mu = E[X]$\n",
    "\n",
    "$a^2P((x-\\mu)^2 \\geq a^2) = a^2 P(|x-\\mu| \\geq a)$\n",
    "\n",
    "\n",
    "## Chebyshev's Inequality\n",
    "\n",
    "Continuous random variable X (with mean $\\mu$ and variance $\\sigma^2$)\n",
    "\n",
    "$$\\sigma^2 = \\int (x-\\mu)^2 f_X(x)\\ dx$$\n",
    "\n",
    "Instead of integrating on full range, integrate on c which is far away from the mean, then we get an inequality\n",
    "\n",
    "$$\\geq \\int_{-\\infty}^{-c} (x-\\mu)^2 f_X(x)\\ dx + \\int_{c}^{\\infty} (x-\\mu)^2 f_X(x)\\ dx$$\n",
    "\n",
    "$$ \\sigma^2 \\geq c^2. P(|X-\\mu| \\geq c)$$\n",
    "\n",
    "The variance is small, the probability that is being far away is small\n",
    "\n",
    "$$P(|X - \\mu| \\geq c) \\leq \\frac{\\sigma^2}{c^2}$$\n",
    "\n",
    "$$P(|X - \\mu| \\geq k\\sigma) \\leq \\frac{1}{k^2}$$\n",
    "\n",
    "Convert c in k times standard deviation away from the mean. If 3 standard deviation from the mean, then at most 1/9 of the class can be 3 standard deviation away from the mean\n",
    "\n",
    "\n",
    "### Convergence of Probability\n",
    "\n",
    "$a_n$ converges to $a$. $a_n$ eventually gets and stays (arbitrarily) close to $a$\n",
    "\n",
    "$$\\lim\\limits_{n \\to \\infty} a_n = a$$\n",
    "\n",
    "Graphically, we draw a vs n. When n is small, the distribution is on larger range. When n becomes bigger and bigger, the distribution is confined between $[a-\\epsilon, a+\\epsilon]$\n",
    "\n",
    "For every $\\epsilon > 0$, there exists $n_0$ such that for every $n \\geq n_0$, we have $|a_n - a | \\leq \\epsilon$\n",
    "\n",
    "Stating on convergence in probability. Sequence of random variable $Y_n$ will get concentrated close to $a$\n",
    "\n",
    "For every $\\epsilon > 0$,\n",
    "\n",
    "$$\\lim\\limits_{n \\to \\infty} P(|Y_n - a| \\geq \\epsilon) = 0$$\n",
    "\n",
    "But convergence in probability doesn't tell you convergence of expected value and variance\n",
    "\n",
    "From the example of slide, pmf of $Y_n$ is $1 - \\frac{1}{n}$ close to 0 and $\\frac{1}{n}$ at n. when n goes to infity, probability of $Y_n = 0$. But $E[Y_n] = 1$ and $E[Y_n^2] = n \\to \\infty$\n",
    "\n",
    "So probabilities on tails are very small, but does not tell us how far it goes\n",
    "\n",
    "\n",
    "### Convergence of the sample mean (Weak law of large numbers)\n",
    "\n",
    "$$M_n = \\frac{X_1 + ... + X_n}{n}$$\n",
    "\n",
    "$$E[M_n] = \\frac{E[X_1] + ... + E[X_n]}{n} = \\frac{n\\mu}{n} = \\mu$$\n",
    "\n",
    "$M_n$ is average of a single expedition. The expectation of $M_n$ is the average of infinite sequence of expeditions\n",
    "\n",
    "Sample mean is a random variable, its expectation is a number\n",
    "\n",
    "$$Var(M_n) = \\frac{n\\sigma^2}{n^2} = \\frac{\\sigma^2}{n}$$\n",
    "\n",
    "The variance/randomness become smaller, when large sample size n is taken\n",
    "\n",
    "Apply Chebyshev's inequality\n",
    "\n",
    "$$P(|M_n - \\mu| \\geq \\epsilon) \\leq \\frac{Var(M_n)}{\\epsilon^2} = \\frac{\\sigma^2}{n\\epsilon^2}$$\n",
    "\n",
    "So for fixed $\\forall \\epsilon > 0$, when n goes to infinity $\\frac{\\sigma^2}{n\\epsilon^2} \\to 0$\n",
    "\n",
    "$$P(|M_n - \\mu| \\geq \\epsilon) \\to 0 $$ \n",
    "\n",
    "This proves that the sample mean converges in probability of the true mean. For the sample mean, when you take average of many many measurements in the sample, then the sample mean is a good estimate of the true mean as it approaches true mean when sample size approaching infinity\n",
    "\n",
    "\n",
    "### Pollster\n",
    "\n",
    "We cannot ask everyone in the population, we can only ask fraction of population f\n",
    "\n",
    "So, the goal reduces to 95% confidence of less than 1% error\n",
    "\n",
    "$$P(|M_n - f| \\geq .01) \\leq .05$$\n",
    "\n",
    "So how large the sample size to satisfy the condition above\n",
    "\n",
    "Apply Chebyshev's inequality\n",
    "\n",
    "$$P(|M_n - f| \\geq .01) \\leq \\frac{\\sigma^2_{M_n}}{0.01^2} = \\frac{\\sigma^2_x}{n(0.01)^2}$$\n",
    "\n",
    "Because it is a Bernouli rv, so $\\sigma^2_x = f(1-f)$. But we don't know f, so we start with the upper bound of the variance. It is a parabola with minimum at 1/2, then gives variance 1/4\n",
    "\n",
    "$$\\frac{\\sigma^2_x}{n(0.01)^2} \\leq \\frac{1}{4n(0.01^2)} \\leq 0.05$$\n",
    "\n",
    "Less than 0.05 so that it satisfies the condition given. Solve for n, we get n = 50,000\n",
    "\n",
    "In other words, if n = 50,000 then $P(|M_n - f| \\geq .01) \\leq .05$ (conservative)\n",
    "\n",
    "50,000 is still a very large sample size, usually we see the pollster has sample size of thousand. This is because Chebyshev's inequality is not tight\n",
    "\n",
    "The other more accurate limit theorem is Central Limit Theorem. It tells us, we can pretend Sn is a normal rv and the calculations just as if it were a normal rv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.5.0",
   "language": "julia",
   "name": "julia-1.5"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
